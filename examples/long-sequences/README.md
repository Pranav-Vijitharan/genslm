# Loooooooong Sequence Lengths

The new [Megatron-DeepSpeed](https://github.com/microsoft/Megatron-DeepSpeed)
release contains a variety of improvements /
optimizations to enable pre-training Transformer based architectures with
significantly longer sequences than was previously possible.

Additional details can be found in the [üìÅ
DeepSpeed4Science](https://github.com/microsoft/Megatron-DeepSpeed/examples_deepspeed/deepspeed4science/megatron_long_seq_support/README.md)
folder.
